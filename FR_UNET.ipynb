{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1De1gs70zcTfipnjLPBj-kfRp7zpdpjaD",
      "authorship_tag": "ABX9TyPfju0uIsrtP/Hu7yPX32qq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hechengw/FR-UNet/blob/master/FR_UNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install latest albumentation"
      ],
      "metadata": {
        "id": "bdFLInuZT8om"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRv3xRSFIr-c",
        "outputId": "a1c049ee-adfe-448c-f257-faadaf4ea97e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/123.5 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m122.9/123.5 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25halbumentations==1.3.0 is successfully installed\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U albumentations\n",
        "!echo \"$(pip freeze | grep albumentations) is successfully installed\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Required Libs"
      ],
      "metadata": {
        "id": "ygk4oJSqURoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/CSE6242')\n",
        "from utils.helpers import dir_exists, remove_files"
      ],
      "metadata": {
        "id": "jrvsNJduUVBV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libs"
      ],
      "metadata": {
        "id": "PkRgb_ohUcEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import copy\n",
        "import random\n",
        "import os\n",
        "import pickle\n",
        "import cv2\n",
        "# import shutil\n",
        "from PIL import Image\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "import albumentations as A\n",
        "import albumentations.augmentations.functional as F\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import Grayscale, Normalize, ToTensor"
      ],
      "metadata": {
        "id": "qXqlwk6nUbew"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Downloand and Process"
      ],
      "metadata": {
        "id": "avy2MKABhERJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download Chest X-ray from Kaggle : "
      ],
      "metadata": {
        "id": "f6fV2IX9hJxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data from google drive\n",
        "def data_process(data_path, name, patch_size, stride, mode):\n",
        "    save_path = os.path.join(data_path, f\"{mode}_pro\")\n",
        "    dir_exists(save_path)\n",
        "    remove_files(save_path)\n",
        "    if name == \"DRIVE\":\n",
        "        img_path = os.path.join(data_path, mode, \"images\")\n",
        "        gt_path = os.path.join(data_path, mode, \"1st_manual\")\n",
        "        file_list = list(sorted(os.listdir(img_path)))\n",
        "    elif name == \"CHASEDB1\":\n",
        "        file_list = list(sorted(os.listdir(data_path)))\n",
        "    elif name == \"STARE\":\n",
        "        img_path = os.path.join(data_path, \"stare-images\")\n",
        "        gt_path = os.path.join(data_path, \"labels-ah\")\n",
        "        file_list = list(sorted(os.listdir(img_path)))\n",
        "    elif name == \"DCA1\":\n",
        "        data_path = os.path.join(data_path, \"Database_134_Angiograms\")\n",
        "        file_list = list(sorted(os.listdir(data_path)))\n",
        "    elif name == \"CHUAC\":\n",
        "        img_path = os.path.join(data_path, \"Original\")\n",
        "        gt_path = os.path.join(data_path, \"Photoshop\")\n",
        "        file_list = list(sorted(os.listdir(img_path)))\n",
        "    img_list = []\n",
        "    gt_list = []\n",
        "    for i, file in enumerate(file_list):\n",
        "        if name == \"DRIVE\":\n",
        "            img = Image.open(os.path.join(img_path, file))\n",
        "            gt = Image.open(os.path.join(gt_path, file[0:2] + \"_manual1.gif\"))\n",
        "            img = Grayscale(1)(img)\n",
        "            img_list.append(ToTensor()(img))\n",
        "            gt_list.append(ToTensor()(gt))\n",
        "\n",
        "        elif name == \"CHASEDB1\":\n",
        "            if len(file) == 13:\n",
        "                if mode == \"training\" and int(file[6:8]) <= 10:\n",
        "                    img = Image.open(os.path.join(data_path, file))\n",
        "                    gt = Image.open(os.path.join(\n",
        "                        data_path, file[0:9] + '_1stHO.png'))\n",
        "                    img = Grayscale(1)(img)\n",
        "                    img_list.append(ToTensor()(img))\n",
        "                    gt_list.append(ToTensor()(gt))\n",
        "                elif mode == \"test\" and int(file[6:8]) > 10:\n",
        "                    img = Image.open(os.path.join(data_path, file))\n",
        "                    gt = Image.open(os.path.join(\n",
        "                        data_path, file[0:9] + '_1stHO.png'))\n",
        "                    img = Grayscale(1)(img)\n",
        "                    img_list.append(ToTensor()(img))\n",
        "                    gt_list.append(ToTensor()(gt))\n",
        "        elif name == \"DCA1\":\n",
        "            if len(file) <= 7:\n",
        "                if mode == \"training\" and int(file[:-4]) <= 100:\n",
        "                    img = cv2.imread(os.path.join(data_path, file), 0)\n",
        "                    gt = cv2.imread(os.path.join(\n",
        "                        data_path, file[:-4] + '_gt.pgm'), 0)\n",
        "                    gt = np.where(gt >= 100, 255, 0).astype(np.uint8)\n",
        "                    img_list.append(ToTensor()(img))\n",
        "                    gt_list.append(ToTensor()(gt))\n",
        "                elif mode == \"test\" and int(file[:-4]) > 100:\n",
        "                    img = cv2.imread(os.path.join(data_path, file), 0)\n",
        "                    gt = cv2.imread(os.path.join(\n",
        "                        data_path, file[:-4] + '_gt.pgm'), 0)\n",
        "                    gt = np.where(gt >= 100, 255, 0).astype(np.uint8)\n",
        "                    img_list.append(ToTensor()(img))\n",
        "                    gt_list.append(ToTensor()(gt))\n",
        "        elif name == \"CHUAC\":\n",
        "            if mode == \"training\" and int(file[:-4]) <= 20:\n",
        "                img = cv2.imread(os.path.join(img_path, file), 0)\n",
        "                if int(file[:-4]) <= 17 and int(file[:-4]) >= 11:\n",
        "                    tail = \"PNG\"\n",
        "                else:\n",
        "                    tail = \"png\"\n",
        "                gt = cv2.imread(os.path.join(\n",
        "                    gt_path, \"angio\"+file[:-4] + \"ok.\"+tail), 0)\n",
        "                gt = np.where(gt >= 100, 255, 0).astype(np.uint8)\n",
        "                img = cv2.resize(\n",
        "                    img, (512, 512), interpolation=cv2.INTER_LINEAR)\n",
        "                cv2.imwrite(f\"save_picture/{i}img.png\", img)\n",
        "                cv2.imwrite(f\"save_picture/{i}gt.png\", gt)\n",
        "                img_list.append(ToTensor()(img))\n",
        "                gt_list.append(ToTensor()(gt))\n",
        "            elif mode == \"test\" and int(file[:-4]) > 20:\n",
        "                img = cv2.imread(os.path.join(img_path, file), 0)\n",
        "                gt = cv2.imread(os.path.join(\n",
        "                    gt_path, \"angio\"+file[:-4] + \"ok.png\"), 0)\n",
        "                gt = np.where(gt >= 100, 255, 0).astype(np.uint8)\n",
        "                img = cv2.resize(\n",
        "                    img, (512, 512), interpolation=cv2.INTER_LINEAR)\n",
        "                cv2.imwrite(f\"save_picture/{i}img.png\", img)\n",
        "                cv2.imwrite(f\"save_picture/{i}gt.png\", gt)\n",
        "                img_list.append(ToTensor()(img))\n",
        "                gt_list.append(ToTensor()(gt))\n",
        "        elif name == \"STARE\":\n",
        "            if not file.endswith(\"gz\"):\n",
        "                img = Image.open(os.path.join(img_path, file))\n",
        "                gt = Image.open(os.path.join(gt_path, file[0:6] + '.ah.ppm'))\n",
        "                cv2.imwrite(f\"save_picture/{i}img.png\", np.array(img))\n",
        "                cv2.imwrite(f\"save_picture/{i}gt.png\", np.array(gt))\n",
        "                img = Grayscale(1)(img)\n",
        "                img_list.append(ToTensor()(img))\n",
        "                gt_list.append(ToTensor()(gt))\n",
        "    img_list = normalization(img_list)\n",
        "    if mode == \"training\":\n",
        "        img_patch = get_patch(img_list, patch_size, stride)\n",
        "        gt_patch = get_patch(gt_list, patch_size, stride)\n",
        "        save_patch(img_patch, save_path, \"img_patch\", name)\n",
        "        save_patch(gt_patch, save_path, \"gt_patch\", name)\n",
        "    elif mode == \"test\":\n",
        "        if name != \"CHUAC\":\n",
        "            img_list = get_square(img_list, name)\n",
        "            gt_list = get_square(gt_list, name)\n",
        "        save_each_image(img_list, save_path, \"img\", name)\n",
        "        save_each_image(gt_list, save_path, \"gt\", name)\n",
        "\n",
        "\n",
        "def get_square(img_list, name):\n",
        "    img_s = []\n",
        "    if name == \"DRIVE\":\n",
        "        shape = 592\n",
        "    elif name == \"CHASEDB1\":\n",
        "        shape = 1008\n",
        "    elif name == \"DCA1\":\n",
        "        shape = 320\n",
        "    _, h, w = img_list[0].shape\n",
        "    pad = nn.ConstantPad2d((0, shape-w, 0, shape-h), 0)\n",
        "    for i in range(len(img_list)):\n",
        "        img = pad(img_list[i])\n",
        "        img_s.append(img)\n",
        "\n",
        "    return img_s\n",
        "\n",
        "\n",
        "def get_patch(imgs_list, patch_size, stride):\n",
        "    image_list = []\n",
        "    _, h, w = imgs_list[0].shape\n",
        "    pad_h = stride - (h - patch_size) % stride\n",
        "    pad_w = stride - (w - patch_size) % stride\n",
        "    for sub1 in imgs_list:\n",
        "        image = F.pad(sub1, (0, pad_w, 0, pad_h), \"constant\", 0)\n",
        "        image = image.unfold(1, patch_size, stride).unfold(\n",
        "            2, patch_size, stride).permute(1, 2, 0, 3, 4)\n",
        "        image = image.contiguous().view(\n",
        "            image.shape[0] * image.shape[1], image.shape[2], patch_size, patch_size)\n",
        "        for sub2 in image:\n",
        "            image_list.append(sub2)\n",
        "    return image_list\n",
        "\n",
        "\n",
        "def save_patch(imgs_list, path, type, name):\n",
        "    for i, sub in enumerate(imgs_list):\n",
        "        with open(file=os.path.join(path, f'{type}_{i}.pkl'), mode='wb') as file:\n",
        "            pickle.dump(np.array(sub), file)\n",
        "            print(f'save {name} {type} : {type}_{i}.pkl')\n",
        "\n",
        "\n",
        "def save_each_image(imgs_list, path, type, name):\n",
        "    for i, sub in enumerate(imgs_list):\n",
        "        with open(file=os.path.join(path, f'{type}_{i}.pkl'), mode='wb') as file:\n",
        "            pickle.dump(np.array(sub), file)\n",
        "            print(f'save {name} {type} : {type}_{i}.pkl')\n",
        "\n",
        "\n",
        "def normalization(imgs_list):\n",
        "    imgs = torch.cat(imgs_list, dim=0)\n",
        "    mean = torch.mean(imgs)\n",
        "    std = torch.std(imgs)\n",
        "    normal_list = []\n",
        "    for i in imgs_list:\n",
        "        n = Normalize([mean], [std])(i)\n",
        "        n = (n - torch.min(n)) / (torch.max(n) - torch.min(n))\n",
        "        normal_list.append(n)\n",
        "    return normal_list\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-dp', '--dataset_path', default=\"datasets/DRIVE\", type=str,\n",
        "                        help='the path of dataset',required=True)\n",
        "    parser.add_argument('-dn', '--dataset_name', default=\"DRIVE\", type=str,\n",
        "                        help='the name of dataset',choices=['DRIVE','CHASEDB1','STARE','CHUAC','DCA1'],required=True)\n",
        "    parser.add_argument('-ps', '--patch_size', default=48,\n",
        "                        help='the size of patch for image partition')\n",
        "    parser.add_argument('-s', '--stride', default=6,\n",
        "                        help='the stride of image partition')\n",
        "    args = parser.parse_args()\n",
        "    with open('config.yaml', encoding='utf-8') as file:\n",
        "        CFG = safe_load(file)  # 为列表类型\n",
        "\n",
        "    data_process(args.dataset_path, args.dataset_name,\n",
        "                 args.patch_size, args.stride, \"training\")\n",
        "    data_process(args.dataset_path, args.dataset_name,\n",
        "                 args.patch_size, args.stride, \"test\")\n"
      ],
      "metadata": {
        "id": "9jHcI8Y6hO5K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}